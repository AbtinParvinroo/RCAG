from typing import Dict, Any, Set, List, Literal, Optional
from pydantic import BaseModel, Field
from jinja2 import Environment
from datetime import datetime
import importlib.util
import zipfile
import shutil
import json
import yaml
import os

class LLMConfig(BaseModel):
    engine: Literal['openai', 'local', 'ollama']
    model_name: str

class RedisConfig(BaseModel):
    host: str = "localhost"
    port: int = 6379
    db: int = 0

class MemoryConfig(BaseModel):
    strategy: Literal['summarization', 'top_k', 'cluster', 'merge_trim', 'graph']
    redis: RedisConfig = Field(default_factory=RedisConfig)
    compressor_params: Dict[str, Any] = Field(default_factory=dict)

class ProjectConfig(BaseModel):
    """Defines the configuration structure specifically for a SAG pipeline."""
    llm: LLMConfig
    memory: MemoryConfig

SAG_MAIN_SCRIPT_TEMPLATE = """
import json
import uuid

# Import SAG components from the 'components' subdirectory
from components.llm import LLMManager
from components.memory_layer import MemoryLayer
from components.compressor import ContextCompressor, BaseCompressionStrategy, SummarizationCompressor, TopKCompressor, ClusterCompressor, MergeAndTrimCompressor, GraphCompressor
from components.prompt_builder import PromptFormatter
from components.embedders import SmartEmbedder # Needed for some compressor strategies

# This configuration was validated and generated by SAGBuilder
CONFIG = {{ config_json }}

def get_compressor_strategy(memory_config: dict, embedder) -> BaseCompressionStrategy:
    \"\"\"Factory function to select and initialize the correct compression strategy.\"\"\"
    strategy_name = memory_config.get('strategy', 'merge_trim')
    params = memory_config.get('compressor_params', {})

    if strategy_name == 'summarization':
        return SummarizationCompressor(**params)
    elif strategy_name in ['top_k', 'cluster']:
        return TopKCompressor(embedder=embedder, **params) if strategy_name == 'top_k' else ClusterCompressor(embedder=embedder, **params)
    elif strategy_name == 'graph':
        return GraphCompressor(**params)
    else: # Default to merge_trim
        return MergeAndTrimCompressor(**params)

def build_sag_pipeline(session_id: str):
    \"\"\"Initializes and wires together all SAG components for a given session.\"\"\"
    print(f"--- Initializing SAG Pipeline for session: {session_id} ---")

    llm = LLMManager(**CONFIG['llm'])

    embedder = None
    if CONFIG['memory']['strategy'] in ['top_k', 'cluster']:
        embedder = SmartEmbedder(model_name='all-MiniLM-L6-v2')
        print(f"[✔] Embedder loaded for compressor: {embedder.model_name}")

    compressor_strategy = get_compressor_strategy(CONFIG['memory'], embedder)
    compressor = ContextCompressor(strategy=compressor_strategy)

    prompt_formatter = PromptFormatter()

    redis_config = CONFIG['memory'].get('redis', {})
    memory_layer = MemoryLayer(session_id=session_id, **redis_config)

    print(f"[✔] LLM loaded: {llm.model_name} ({llm.engine})")
    print(f"[✔] Memory Layer connected to Redis at {redis_config.get('host', 'localhost')}")
    print(f"[✔] Memory strategy set to: {compressor.strategy.__class__.__name__}")
    print("--- SAG Pipeline is Ready ---")

    return llm, memory_layer, compressor, prompt_formatter

def run_interactive_chat(llm, memory, compressor, formatter):
    \"\"\"Runs the main interactive loop for the SAG chatbot.\"\"\"
    print("\\n--- Running Interactive Chat (type 'exit' to quit) ---")

    while True:
        query = input("You: ")
        if query.lower() in ['exit', 'quit']:
            print("Goodbye!")
            break

        history = memory.format_for_prompt()
        context = ""
        if history:
            compressed_history = compressor.compress(chunks=history, query=query)
            context = "\\n".join(compressed_history) if isinstance(compressed_history, list) else compressed_history

        memory.add_message(role="user", content=query)
        response_stream = llm.generate(prompt=query, context=context, stream=True)

        print("Bot: ", end="", flush=True)
        full_response = ""
        for chunk in response_stream:
            print(chunk, end="", flush=True)
            full_response += chunk
        print() # Newline after response

        memory.add_message(role="assistant", content=full_response)

if __name__ == "__main__":
    session_id = f"chat_session_{uuid.uuid4().hex[:8]}"
    llm_pipeline, memory_layer, ctx_compressor, prompt_formatter = build_sag_pipeline(session_id)
    run_interactive_chat(llm_pipeline, memory_layer, ctx_compressor, prompt_formatter)
"""

class SAGBuilder:
    """An intelligent project builder that scaffolds a customized SAG pipeline."""
    def __init__(self, project_name: str, config: Dict[str, Any]):
        self.project_name = project_name
        self.config: ProjectConfig = ProjectConfig.parse_obj(config)
        self.output_dir = os.path.join(os.getcwd(), self.project_name)
        self.component_map = {
            "llm": "llm", "memory_layer": "memory_layer", "compressor": "compressor",
            "prompt_builder": "prompt_builder", "embedder": "embedders",
        }

        self.dependency_map = {
            "llm": ["requests", "openai"], "memory_layer": ["redis"],
            "compressor": ["scikit-learn", "transformers", "numpy", "spacy", "networkx"],
            "prompt_builder": ["pandas", "numpy"], "embedder": ["sentence-transformers", "torch"],
        }

    @classmethod
    def from_yaml(cls, project_name: str, config_path: str):
        with open(config_path, 'r') as f:
            config_dict = yaml.safe_load(f)

        return cls(project_name, config_dict)

    def _prepare_output_dir(self):
        if os.path.exists(self.output_dir):
            shutil.rmtree(self.output_dir)

        os.makedirs(os.path.join(self.output_dir, "components"), exist_ok=True)

    def _copy_component_file(self, component_filename: str):
        source_path = os.path.join("sag_components", f"{component_filename}.py")
        if not os.path.exists(source_path):
            raise FileNotFoundError(f"Source file not found: {source_path}")

        destination_path = os.path.join(self.output_dir, "components", f"{component_filename}.py")
        shutil.copy(source_path, destination_path)
        print(f"[✔] Copied component: {component_filename}.py")

    def _create_main_script(self):
        env = Environment()
        template = env.from_string(SAG_MAIN_SCRIPT_TEMPLATE)
        script_content = template.render(config_json=self.config.model_dump_json(indent=4))
        path = os.path.join(self.output_dir, "main.py")
        with open(path, "w", encoding="utf-8") as f:
            f.write(script_content.strip())

        print("[✔] Generated main.py for SAG pipeline")

    def _create_requirements_file(self, dependencies: Set[str]):
        dependencies.update(["pydantic", "pyyaml", "jinja2"])
        path = os.path.join(self.output_dir, "requirements.txt")
        with open(path, "w") as f:
            for dep in sorted(list(dependencies)):
                f.write(f"{dep}\n")

        print("[✔] Generated requirements.txt")

    def build(self):
        print(f"--- Building SAG Project: {self.project_name} ---")
        self._prepare_output_dir()
        components_to_copy = ["llm", "memory_layer", "compressor", "prompt_builder"]
        required_deps = set()

        if self.config.memory.strategy in ['top_k', 'cluster']:
            components_to_copy.append("embedder")

        for component_name in components_to_copy:
            self._copy_component_file(component_name)
            required_deps.update(self.dependency_map.get(component_name, []))

        self._create_requirements_file(required_deps)
        self._create_main_script()
        zip_path = shutil.make_archive(self.project_name, 'zip', self.output_dir)
        print(f"--- Build Complete! Project zipped at: {zip_path} ---")
        return zip_path