from typing import Dict, Any, Set, List, Literal, Optional
from pydantic import BaseModel, Field
from jinja2 import Environment
from datetime import datetime
import importlib.util
import zipfile
import shutil
import json
import yaml
import os

class VectorStoreConfig(BaseModel):
    backend: Literal['faiss', 'qdrant', 'chroma']
    dim: int = 384

class LLMConfig(BaseModel):
    engine: Literal['openai', 'local', 'ollama']
    model_name: str

class EmbedderConfig(BaseModel):
    model_name: str = "all-MiniLM-L6-v2"

class PostProcessorConfig(BaseModel):
    steps: List[str] = ["clean"]

class ProjectConfig(BaseModel):
    """Defines the configuration structure for a RAG pipeline."""
    vector_store: VectorStoreConfig
    llm: LLMConfig
    embedder: EmbedderConfig = Field(default_factory=EmbedderConfig)
    post_processor: PostProcessorConfig = Field(default_factory=PostProcessorConfig)
    chunker: Dict[str, Any] = Field(default_factory=dict)
    retriever: Dict[str, Any] = Field(default_factory=dict)

MAIN_SCRIPT_TEMPLATE = """
import os
import json
# Import all RAG components from the 'components' subdirectory
from components.embedder import SmartEmbedder
from components.vector_db import SmartVectorStore
from components.retriever import Retriever
from components.llm import LLMManager
from components.chunker import RAGChunker
from components.post_processor import PostProcessor, CleaningStep, RelevanceCheckStep

# This configuration was validated and generated by RAGBuilder
CONFIG = {{ config_json }}

def build_full_pipeline():
    \"\"\"Initializes and wires together all RAG components based on the generated config.\"\"\"
    print("--- Initializing RAG Pipeline from Config ---")

    # 1. Instantiate Core RAG Components
    embedder = SmartEmbedder(**CONFIG.get('embedder', {}))
    vector_store = SmartVectorStore(**CONFIG.get('vector_store', {}))
    retriever = Retriever(embedder=embedder, vector_store=vector_store, **CONFIG.get('retriever', {}))
    llm = LLMManager(**CONFIG.get('llm', {}))
    chunker = RAGChunker(**CONFIG.get('chunker', {}))

    # 2. Instantiate Post-Processor (The new QC step)
    post_processor_steps = []
    pp_config = CONFIG.get('post_processor', {})
    if 'clean' in pp_config.get('steps', []):
        post_processor_steps.append(CleaningStep())
    if 'relevance_check' in pp_config.get('steps', []):
        post_processor_steps.append(RelevanceCheckStep())
    post_processor = PostProcessor(steps=post_processor_steps)

    print("--- Pipeline is Ready ---")
    return llm, vector_store, embedder, chunker, post_processor

def run_example(llm, post_processor):
    \"\"\"Runs a sample query to demonstrate the pipeline.\"\"\"
    print("\\n--- Running Example Query ---")
    query = "What are the main challenges in deploying large language models?"
    print(f"Query: {query}")

    try:
        response_stream = llm.generate(prompt=query, stream=True)
        raw_response = "".join(list(response_stream))

        print("\\n--- Raw LLM Output ---")
        print(raw_response)

        processing_results = post_processor.process(raw_response, context={"query": query})
        final_response = processing_results.get("processed_text", raw_response)

        print("\\n--- Final, Processed Answer ---")
        print(final_response)

        if "RelevanceCheckStep" in processing_results:
            print(f"Relevance Score: {processing_results['RelevanceCheckStep']['relevance_score']:.2f}")

    except Exception as e:
        print(f"\\nAn error occurred: {e}")

if __name__ == "__main__":
    llm_pipeline, vs, emb, chk, pp = build_full_pipeline()
    run_example(llm_pipeline, pp)
"""

class RAGBuilder:
    """
    An intelligent project builder that scaffolds a customized RAG pipeline.
    """
    def __init__(self, project_name: str, config: Dict[str, Any]):
        self.project_name = project_name
        self.config: ProjectConfig = ProjectConfig.parse_obj(config)
        self.output_dir = os.path.join(os.getcwd(), self.project_name)
        self.component_map = {
            "llm": "llm", "embedder": "embedder", "vector_db": "vector_db",
            "retriever": "retriever", "chunker": "chunker", "post_processor": "post_processor",
        }

        self.dependency_map = {
            "llm": ["requests", "openai"], "embedder": ["sentence-transformers", "torch"],
            "vector_db": ["faiss-cpu", "qdrant-client", "chromadb", "weaviate-client", "pymilvus"],
            "retriever": [], "chunker": ["pydub", "opencv-python", "Pillow"],
            "post_processor": ["scikit-learn", "spacy", "openai"],
        }

    @classmethod
    def from_yaml(cls, project_name: str, config_path: str):
        with open(config_path, 'r') as f:
            config_dict = yaml.safe_load(f)

        return cls(project_name, config_dict)

    def _prepare_output_dir(self):
        if os.path.exists(self.output_dir):
            shutil.rmtree(self.output_dir)

        os.makedirs(os.path.join(self.output_dir, "components"), exist_ok=True)

    def _copy_component_file(self, component_filename: str):
        source_path = os.path.join("rag_components", f"{component_filename}.py")
        if not os.path.exists(source_path):
            raise FileNotFoundError(f"Source file not found: {source_path}")

        destination_path = os.path.join(self.output_dir, "components", f"{component_filename}.py")
        shutil.copy(source_path, destination_path)
        print(f"[✔] Copied component: {component_filename}.py")

    def _create_main_script(self):
        env = Environment()
        template = env.from_string(MAIN_SCRIPT_TEMPLATE)
        script_content = template.render(config_json=self.config.model_dump_json(indent=4))
        path = os.path.join(self.output_dir, "main.py")
        with open(path, "w", encoding="utf-8") as f:
            f.write(script_content.strip())

        print("[✔] Generated main.py for RAG pipeline")

    def _create_requirements_file(self, dependencies: Set[str]):
        dependencies.update(["pydantic", "pyyaml", "jinja2"])
        path = os.path.join(self.output_dir, "requirements.txt")
        with open(path, "w") as f:
            for dep in sorted(list(dependencies)):
                f.write(f"{dep}\n")

        print("[✔] Generated requirements.txt")

    def build(self):
        print(f"--- Building RAG Project: {self.project_name} ---")
        self._prepare_output_dir()

        components_to_copy = list(self.component_map.keys())
        required_deps = set()

        for component_name in components_to_copy:
            filename = self.component_map[component_name]
            self._copy_component_file(filename)
            required_deps.update(self.dependency_map.get(component_name, []))

        self._create_requirements_file(required_deps)
        self._create_main_script()
        zip_path = shutil.make_archive(self.project_name, 'zip', self.output_dir)
        print(f"--- Build Complete! Project zipped at: {zip_path} ---")
        return zip_path